{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JafiSIrvEKW"
      },
      "source": [
        "Welcome to Week 5!\n",
        "\n",
        "We will be focussing in Particle Physics Analysis and detecting matter/antimatter assymetries in the production of certain types of particles. ![LHCb detector](https://www1b.physik.rwth-aachen.de/~schael/LHCb_files/LHCB%20PREVIEW-white-bg.jpg)\n",
        "\n",
        "The data we are using comes from LHCb - one of the experiments at LHC. It is a highly specialised detector aimed at detecting decays involving the B-quark. Unlike the other major experiments, LHCb detects particles very close to the source and looks almost exclusively in the forward direction - this gives the detector many advantages compared to other experiments at LHC.\n",
        "\n",
        "In order to get started, we need to access the [ROOT framework](https://root.cern.ch/) and download some datafiles into this machine.\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFclIR72w0mU",
        "collapsed": true
      },
      "source": [
        "In the Terminal run the following:\n",
        "\n",
        "conda config --set channel_priority strict\n",
        "conda create -c conda-forge --name my-root-env root\n",
        "\n",
        "Then return to the launcher and you should see \"Python [Conda env: my-root-env]\"\n",
        "\n",
        "Then open the Jupyter notebook for this week and go Kernal -> Change Kernal -> select \"Python [Conda env: my-root-env]\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this once per kernal crash\n",
        "!wget https://github.com/MohamedElashri/ROOT/releases/download/ubuntu/root_v6.28.04_Ubuntu_20.04.zip\n",
        "!unzip /content/root_v6.28.04_Ubuntu_20.04.zip\n",
        "!apt-get install git dpkg-dev cmake g++ gcc binutils libx11-dev libxpm-dev libxft-dev libxext-dev tar gfortran subversion\n",
        "!apt-get inatall libpython3.6-dev"
      ],
      "metadata": {
        "id": "RJbV2SbQsbfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following is needed because colab upgraded the openssl library\n",
        "!wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb"
      ],
      "metadata": {
        "id": "rcWEZcMLscTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/root_build/\")\n",
        "sys.path.append(\"/content/root_build/bin/\")\n",
        "sys.path.append(\"/content/root_build/include/\")\n",
        "sys.path.append(\"/content/root_build/lib/\")\n",
        "import ctypes\n",
        "ctypes.cdll.LoadLibrary('/content/root_build/lib//libCore.so')\n",
        "ctypes.cdll.LoadLibrary('/content/root_build/lib//libThread.so')\n",
        "ctypes.cdll.LoadLibrary('/content/root_build/lib//libTreePlayer.so')\n"
      ],
      "metadata": {
        "id": "I9x8EUCCsc1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTVz7NQMyDCb"
      },
      "source": [
        "#Now we can check if we have everything working as we expect:\n",
        "#Import brings the ROOT framework into our python environment.\n",
        "import ROOT\n",
        "#We define a 1 dimensional histogram, with 100 bins which ranges from -4 to +4\n",
        "h = ROOT.TH1F(\"gauss\",\"Example histogram\",100,-4,4)\n",
        "#Fill the histogram with gaussian (random) distribution\n",
        "h.FillRandom(\"gaus\")\n",
        "#make a Canvas (i.e. a drawing)\n",
        "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",800,600)\n",
        "#Draw my histogram\n",
        "h.Draw()\n",
        "#Show me the canvas\n",
        "c.Draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXW1M6XB0tXP"
      },
      "source": [
        "All being well - this should give no errors and we should have some kind of Gaussian distribution above.\n",
        "\n",
        "The next step is to get our data file - you can find it on Canvas here: https://canvas.maastrichtuniversity.nl/courses/17323/files/3634864?module_item_id=644095\n",
        "\n",
        "Then upload it directly. You can also run the following:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir LHCb_Data && cd LHCb_Data && wget http://opendata.cern.ch/record/4900/files/B2HHH_MagnetDown.root"
      ],
      "metadata": {
        "id": "cJgZsPT2PBKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co476pbmBvBB"
      },
      "source": [
        "\n",
        "#Since we need to use ROOT, we must first import this into Python:\n",
        "import ROOT\n",
        "#Then we open the ROOT file using the TFile command. - note you need to make this file path correct for your own setup!\n",
        "f = ROOT.TFile.Open(\"/content/drive/MyDrive/B2HHH_MagnetUp.root\", \"READONLY\")\n",
        "#From our file, we have to extract the DecayTree\n",
        "tree=f.Get(\"data\")\n",
        "#Now we can grab some variables as a test:\n",
        "ymomentum = ROOT.RooRealVar(\"H1_PY\",\"H1 Y Momentum\",-3000,3000,\"MeV/c\")\n",
        "xmomentum = ROOT.RooRealVar(\"H1_PX\",\"H1 X Momentum\",-3000,3000,\"MeV/c\")\n",
        "zmomentum = ROOT.RooRealVar(\"H1_PZ\",\"H1 Z Momentum\",-3000,3000,\"MeV/c\")\n",
        "# We then create a dataset for us to play with\n",
        "data = ROOT.RooDataSet(\"data\",\"data set\", tree, ROOT.RooArgSet(xmomentum,ymomentum,zmomentum), \"1==1\")\n",
        "# Now we create a canvas, plot our data onto the canvas and draw it:\n",
        "c = ROOT.TCanvas(\"c\",\"c\")\n",
        "frame = xmomentum.frame()\n",
        "data.plotOn(frame)\n",
        "frame.Draw()\n",
        "c.Draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4n4iS3IJZi"
      },
      "source": [
        "#Why are we here?\n",
        "\n",
        "This week is about finding out something about one of the fundemental questions in physics. Why do we have \"stuff\".\n",
        "\n",
        "According to many of our models, and according to many measurements in particle physics, matter and anti-matter appear to be produced in equal quantities.\n",
        "\n",
        "However, when one looks at the Universe in general, we have more matter than anti-matter left - so there need to be some processes where anti-matter and matter are not produced equally. You can find out more about the Matter/Anti-Matter Asymmetry [here](http://press.web.cern.ch/backgrounders/matterantimatter-asymmetry)\n",
        "\n",
        "One place we look for this asymetry is in [charge-partity (CP) violation](https://www.symmetrymagazine.org/article/october-2005/explain-it-in-60-seconds) in particle physics processes. This essentially says that the processes that happen in the anti-particle version of a decay do not **exactly** match to the processes that happen in the particle version of the decay.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "At LHCb, we produce both particle of the  B<sup>+</sup> meson and it's antiparticle the B<sup>-</sup> meson.\n",
        "\n",
        "We cannot detect these mesons directly. They decay into other things before we have a chance to measure them properly. So we collect data on the decay products, often called daughter particles. There are 524 [documented](http://pdg.lbl.gov/2014/listings/rpp2014-list-B-plus-minus.pdf) ways that the B<sup>+/-</sup> decays into various combinations. In order to simplify the process, we choose decay combinations that are convenient or have particular properties.\n",
        "\n",
        "In this analysis, we will take the process:-\n",
        "\n",
        "B<sup>+</sup>->K<sup>+</sup> + K<sup>+</sup>  + K<sup>-</sup>\n",
        "\n",
        "or\n",
        "\n",
        "B<sup>-</sup>->K<sup>-</sup> + K<sup>-</sup>  + K<sup>+</sup>\n",
        "\n",
        "\n",
        "To do so, we are given the following data for each event in our system:-\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/lhcb/opendata-project/80d64a3796e593fc8f9b257e85f32ae2e54f131f/Images/Variables.png)\n",
        "\n",
        "Here, H1 is the detected daughter particle (so a Kaon or a Pion), **not** the B-meson - the mother particle. Normally we would have to do some reconstruction from the decay products (the Daughters) to the Mother to be able to make some conclusions.\n",
        "\n",
        "Let's get started with working with this data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOhfj7kfP-ao"
      },
      "source": [
        "For our analysis, the momentum of each of the daughter particles is split into the three cartesian components. We have combined these into a variable called H1_Ptot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4keyoyTPjsK"
      },
      "source": [
        "#Here make a plot of the Total momentum of each of the three daughters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1lXLMCoR1Gi"
      },
      "source": [
        "Now plot the total momentum for the mother (M_Ptot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kdbiNpPR1QG"
      },
      "source": [
        "#use the histogram plotting tools, plot the momentum of the mother"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj5qv5kqSMIF"
      },
      "source": [
        "Let's take a look at the whole data file that is available to us by looking at one specific entry - number 45"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMkih_6SSG8I"
      },
      "source": [
        "tree.Show(45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3sqwtNTUEJd"
      },
      "source": [
        "We have now completed the initial steps and begun to work through what we need to with the data. This is a perfect moment to take a coffee!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RhWWqt3a8_e"
      },
      "source": [
        "Having discovered all of the relevant information about our daughter particles, we need to combine the measurements about them into a single mother - which will be our B<sup>+</sup> or our B<sup>-</sup>\n",
        "\n",
        "Having found our momentum and energy, we can use these quantities to find our experimental mass (not the theoretical mass as we have used for the reconstruction).\n",
        "\n",
        "When we calculate this, we will get a distribution of masses. This is due to errors in the measurements made either by the detector, or in the experiment itself. We hope to have a reasonably narrow peak to work with, but, sometimes this is not possible.\n",
        "\n",
        "Additionally there will be other particles in the detector - which means our daughters might have come from two or even three different processes. Events which don't come from the same process will give a higher or lower mass than we are looking for. This is typically called the *background* while events which come from our event of interest are called the *signal*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onr7-8CMbbFf"
      },
      "source": [
        "#Now plot a histogram of the range of masses of the B meson.\n",
        "#Does this match what we would expect from theory?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWGFKFnXb0RP"
      },
      "source": [
        "We know that some of our particles are the B+ and some are the B- particle. There will also be some particles in our system that are not coming from a genuine B+/- or are a B+/- but are not constructed from Kaons.\n",
        "\n",
        "We have some tools available to help:-\n",
        "\n",
        "  *  During detection, software attributes the probability of a particle being a Kaon or a Pion (in the H1_ProbK or H1_ProbPi variable)\n",
        "  * The detector also knows if the particle was a Muon - since it has detectors specifically for these. So it can attribute a 0 or a 1 to this probability\n",
        "  * The reconstructed vertex has a some kind of quality associated with it (we call this the Vertex χ2 (this is the variable B_VertexChi2). This is the statistical measure that determines how well we found a single point to be the source of all three particles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEpnSmH4b9HZ"
      },
      "source": [
        "In order to get a better result, we should select our data to have the properties we desire and make some rules (often called a selection) to cut away data we don't want to include for various reasons. e.g. we know we don't have any muons in our decay - so any time H1/H2/H3 are a muon they should be excluded. The other variables are not so clear - so we can plot them to make a decision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0vikJp0cAvv"
      },
      "source": [
        "#Make plots of H1/H2/H3 _ProbK on one plot\n",
        "#Make plots of H1/H2/H3 _ProbPi on one plot\n",
        "#For all our particles, make a plot of the B_VertexChi2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWmxBkZ0cDx1"
      },
      "source": [
        "Using these plots, we can now make a preselection string. This is a text string that looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1IGKyZXcGJP"
      },
      "source": [
        "#This example is for each daughter particle to have a Probability of being a Pion being more than 90% and H1 to not be a muon\n",
        "#This is not a good choice of selection - you should make your own :)\n",
        "selection=(\"H1_ProbPi>0.9&H2_ProbPi>0.9&H3_ProbPi>0.9&!H1_isMuon&H2_isElectron&H3_isElephant\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxD7JMeicMu0"
      },
      "source": [
        "#To apply the selection - we can use the copytree command:\n",
        "selection=(\"H1_ProbK>0.9\")\n",
        "CutTree=tree.CopyTree(selection)\n",
        "\n",
        "#So now we take our data in tree and apply selection to it (so only events which comply with those rules are kept) and put the new data in CutTree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmmsoUwEcOir"
      },
      "source": [
        "#Now as a good check, we should see the effect of applying our cuts.\n",
        "#On one histogram, plot the B meson mass, from both the tree (pre-cuts) and the CutTree (post-cuts)\n",
        "#What do you notice about your histogram now?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1tResqvcMgQ"
      },
      "source": [
        "#How do we count the number of events?\n",
        "\n",
        "We now have a histogram of events that we have reconstructed as a B meson. But some of these events are caused by a co-incidence of events which would still occur if there were no B mesons actually produced. We call this the background. Background and signal are indistinguishable now as the detector cannot tell the difference and our cuts were unable to remove the events for physics reasons. We can do some statistical analysis, if we know the approximate shapes of our signal and our background. Just like a least-squares fitting we can run a fit routine to minimise the error between the fitted curve and our data. As an example, if we know our data has an exponential background and a gaussian signal:\n",
        "\n",
        "![Gaussian+Exp Background](https://twiki.cern.ch/twiki/pub/RooStats/RooStatsTutorialsJune2013/GausExpModelFit.png)\n",
        "\n",
        "Here the red line represents our signal, the blue dotted line is our background and the solid blue line is our combined curve. The graph also shows the number of signal events and the number of background events. The signal now is a tiny fraction of the total data shown in the plot.\n",
        "\n",
        "In order to do this, we need to build a fit model, around which the software can try to fit our data.\n",
        "\n",
        "We use RooFit for this, which includes:\n",
        "* Gaussian\n",
        "* Exponential\n",
        "* Chebychev\n",
        "* Crystal Ball\n",
        "* Breit-Wigner\n",
        "\n",
        "As well as several other choices.\n",
        "\n",
        "Typically exponential and Chebychev functions are used for background and Gaussian, Crystal Ball and Breit-Wigner are used for signal. We can also combine them (e.g. 1 crystal ball, 1 gaussian, 1 exponential) in various ways."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_7q_HY1qhiS"
      },
      "source": [
        "#define physical measurment that we want to fit using RooRealVar\n",
        "# var = ROOT.RooRealVar =(\"Variable from Python\", \"Nickname\",Min, Max, Units)\n",
        "mass = ROOT.RooRealVar(\"M_m0\",\"Mass\",4700,5900,\"MeV/C^{2}\")\n",
        "\n",
        "#passing the rest of the variables into the model\n",
        "#For the RooRealVar the last three parameters are given, \"starting value\" and min/max values\n",
        "gaussMean = ROOT.RooRealVar(\"Mean\",\"Mean\",4800,4900,5900)\n",
        "gaussWidth = ROOT.RooRealVar(\"Width\",\"Width\",40,0,7000)\n",
        "\n",
        "#Now we have enough to make our Model for the signal:\n",
        "\n",
        "Gauss=ROOT.RooGaussian(\"Gaussian Signal\",\"Gauss\",mass,gaussMean,gaussWidth)\n",
        "Gauss_Norm= ROOT.RooRealVar(\"Gauss_Norm\",\"Signal Yield\", tree.GetEntries()/30, 0, tree.GetEntries() * 3)\n",
        "#We also need a background, so let's use a (simple) exponential:\n",
        "\n",
        "exponent=ROOT.RooRealVar(\"exponent\", \"C\", -0.02, -2, +2)\n",
        "exp_Norm= ROOT.RooRealVar(\"exp_Norm\",\"Background Yield\", tree.GetEntries()/30, 0, tree.GetEntries() * 2)\n",
        "\n",
        "#Define the  model for the background:\n",
        "\n",
        "Bkgnd=ROOT.RooExponential(\"Exponential Background\",\"Bkgnd\",mass,exponent)\n",
        "\n",
        "#Now we need to combine these two functions into a single PDF (probability density function)\n",
        "#and we need to add the normalisation factors at the end as scaling factors\n",
        "\n",
        "model=ROOT.RooAddPdf(\"Full Model\",\"model\",ROOT.RooArgList(Gauss,Bkgnd),ROOT.RooArgList(Gauss_Norm, exp_Norm) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL-qVvs-dw86"
      },
      "source": [
        "#Put our data set into a RooDataSet structure\n",
        "\n",
        "data_to_fit=ROOT.RooDataSet(\"Data Set\",\"data_to_fit\", CutTree, ROOT.RooArgSet(mass))\n",
        "\n",
        "#Then we can do the fitting:\n",
        "\n",
        "model.fitTo(data_to_fit)\n",
        "\n",
        "#if everything went well, you will see the outputs of RooFit below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUhgxlRGd4XO"
      },
      "source": [
        "#Now to plot it all\n",
        "c1=ROOT.TCanvas(\"c1\",\"c1\")\n",
        "frame=mass.frame()\n",
        "data_to_fit.plotOn(frame)\n",
        "model.plotOn(frame, ROOT.RooFit.Components(\"Gauss\"),ROOT.RooFit.LineColor(8),ROOT.RooFit.LineStyle(2))\n",
        "model.plotOn(frame, ROOT.RooFit.Components(\"Bkgnd\"),ROOT.RooFit.LineColor(46),ROOT.RooFit.LineStyle(2))\n",
        "model.plotOn(frame)\n",
        "frame.Draw()\n",
        "c1.Update()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60b4bs1od4M_"
      },
      "source": [
        "Using this structure, you can in theory build whatever models you like!\n",
        "\n",
        "Some recommendations (but not necessary to do all):-\n",
        "\n",
        "\n",
        "\n",
        "*   Gauss+Exponential (as above)\n",
        "*   Crystal Ball + Exponential\n",
        "*   Gauss+Crystal Ball+Exponential (now you need to weigh the two signal peaks and then the total signal against total background)\n",
        "*   Gauss+Chebychev\n",
        "*   Two Crystal Balls + Exponential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHivSaH1dwy7"
      },
      "source": [
        "So how good was the fit, and how many events do you have?\n",
        "\n",
        "We can use the .getValV() function on our signal and background *normalisation* components, e.g. Gauss_Norm=Gauss.getValV()\n",
        "\n",
        "To find the error (on this number) we can use .getError()\n",
        "\n",
        "Neither of these measures would tell us if this was a good fit or not. Normally we use a χ2 test to do so - this is built into the image we made (so we can do frame.chiSquare() to get this data)\n",
        "\n",
        "For each model you made, print the signal and background yields (with errors) and report the χ2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob2HARgWoTGe"
      },
      "source": [
        "#Counting\n",
        "\n",
        "So we have now loaded our data; we have reconstructed information about the mother B meson and we have cut away any data which looks like it might not be what we are looking for. We have then plotted histograms of the mass of the B meson and used this to fit a model, a function to describe the events there. We now have to identify which of our events belong to the B<sup>+</sup> and how many of them belong to B<sup>-</sup>.\n",
        "\n",
        "To do this, should split out data into two groups (and throw away data which doesn't comply with either decay)\n",
        "\n",
        "We will be looking for the events which are\n",
        "\n",
        "\n",
        "B<sup>+</sup>->K<sup>+</sup> + K<sup>+</sup>  + K<sup>-</sup>\n",
        "\n",
        "or\n",
        "\n",
        "B<sup>-</sup>->K<sup>-</sup> + K<sup>-</sup>  + K<sup>+</sup>\n",
        "\n",
        "We can look for the number of positive and negative charges in H1, H2 and H3 (using the variable ```H1_Charge``` etc.). If we have 0 or 3 positive charges, we should throw the event away and if we have 1 it should be assigned be a B<sup>-</sup>, with 2 it should be a B<sup>+</sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8VB5uN1obc4"
      },
      "source": [
        "Once we have defined if it's a B<sup>+</sup> or a B <sup>-</sup>, we should go ahead and ensure the pre-selection is applied and then plot our B mass, and fit the model to find the yield.\n",
        "\n",
        "We can then calculate the assymetry from this equation:\n",
        "\n",
        "$A=\\frac{(N^{B-}-N^{B+})}{(N^{B-}+N^{B+})}$\n",
        "\n",
        "Where N<sup>B+/- </sup> is the number of events found from the fitted yield of the signal from each data set.\n",
        "\n",
        "The uncertainty on this result is given by:\n",
        "\n",
        "$\\sigma_A=\\sqrt\\frac{1-A^2}{N^{B-}+N^{B+}}$\n",
        "\n",
        "Calculate these two values for your data and print them below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiPNe2iuobSK"
      },
      "source": [
        "#Here do your calculation of the final result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5B--_33okz1"
      },
      "source": [
        "#Congratulations!\n",
        "\n",
        "You just made your first LHCb physics analysis. Does this seem like a reasonable result? Did we explain why we have an excess of mass in the Universe?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzybWZylomGu"
      },
      "source": [
        "## **Bonus content only below here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odpbRqdoou5M"
      },
      "source": [
        "To make a further anaysis, we can look into the intermediate processes.\n",
        "\n",
        "We have so far considered only that the B meson ultimately decays into three kaons. It may be that on the way, the B meson first decays into a Kaon and another particle, and then from that particle to two Kaons.\n",
        "\n",
        "We would expect this to be one of three possible modes (for B<sup>+</sup>):\n",
        "\n",
        "$R^{++} \\rightarrow K_1^+ +K_2^+$\n",
        "\n",
        "(we don't expect this to happen because of the like charges in the Kaons)\n",
        "\n",
        "$R^0 \\rightarrow K_1^+ +K_3^-$\n",
        "\n",
        "$R^0 \\rightarrow K_2^+ +K_3^-$\n",
        "\n",
        "(Expect symmetric arrangements for B<sup>-</sup>)\n",
        "\n",
        "To analyse the intermediate states we can measure the invarient masses of the intermediate states and then plot them on what is called a Dalitz plot (this is a 2D plot with two different two body decays (from the three body decay) on each axis)\n",
        "\n",
        "![Dalitz Plot](https://slideplayer.com/slide/15960097/88/images/15/Dalitz+plot%3A+%CE%9B+c+%2B+%E2%86%92%F0%9D%91%9D+%F0%9D%90%BE+%E2%88%92+%F0%9D%9C%8B+%2B.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqJxvZSKo1cW"
      },
      "source": [
        "#Define a function to find the invarient mass of two given Kaons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPVqECfPo3Wc"
      },
      "source": [
        "#Then, ensuring you're still taking the data after the selection, make a Dalitz plot. This is a 2-D scatter plot (use e.g. TH2F to make the plot where we used TH1F before)\n",
        "#Choose an appropriate binning in your scatter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPoPLt4Uo6QB"
      },
      "source": [
        "We can further improve our plot, since two sets of particles on each axis are exactly the same (one positive Kaon, one negative Kaon). So we can plot the maximum of the two values on one axis and the minimum on the other. We can use a quick numpy check and then plot those values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ_fe2R3o8Aq"
      },
      "source": [
        "#Make the revised Dalitz plot here for B+ mesons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t46slV8Yo-Ed"
      },
      "source": [
        "#Make the revised Dalitz plot here for B- mesons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfTDh69qo9_q"
      },
      "source": [
        "#Where we have a higher density of points (or a bigger value in the bin) this is indication of an intermediate resonance\n",
        "#Check out the possible resonances you have found in the PDG (http://pdg.lbl.gov/2020/tables/contents_tables.html)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}